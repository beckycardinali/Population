{"cells":[{"cell_type":"markdown","metadata":{},"source":["## Sources of Assessment\n\n"]},{"cell_type":"markdown","metadata":{},"source":["Your grade in EEP153 will be based on four different sources:\n\n1.  Other's ranking of your teams' performance on each class project;\n\n2.  Your teammates' rankings of your contribution to each project;\n\n3.  An individual final exam; and\n\n4.  Some extra credit opportunities, including activity on `piazza`.\n\n"]},{"cell_type":"markdown","metadata":{},"source":["## Data from Assessments\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### Students\n\n"]},{"cell_type":"markdown","metadata":{},"source":["Consider the following artificial data on assessment.  We first\ngenerate some data on (imaginary) students.  Each student is\ncharacterized by three things:\n\n-   Name (to identify student; we observe this);\n-   Ability (affects performance independent of effort);\n-   Effort (affects performance independent of ability);\n\nThe following code defines a function we can use to generate some random names for our imaginary students.\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import pandas as pd\nimport numpy as np\nimport urllib.request\nimport random\n\ndef random_names(n,k=2):\n    \"\"\"Return a list of n random k-part names.\n\n    Borrows from =amoodie='s amusing idea described at\n    https://stackoverflow.com/questions/18834636/random-word-generator-python\n    \"\"\"\n    word_url = \"http://svnweb.freebsd.org/csrg/share/dict/words?view=co&content-type=text/plain\"\n    response = urllib.request.urlopen(word_url)\n    long_txt = response.read().decode()\n    words = long_txt.splitlines()\n    upper_words = [word for word in words if word[0].isupper()]\n    name_words  = [word for word in upper_words if not word.isupper()]\n    rand_name   = ' '.join([name_words[random.randint(0, len(name_words))]\n                            for i in range(k)])\n\n    names = []\n    for i in range(n):\n        names.append(' '.join([name_words[random.randint(0,len(name_words))]\n                               for j in range(k)]))\n\n    return names\n\nSTUDENTS = 40\nnames = random_names(STUDENTS)\n# print(names)"]},{"cell_type":"markdown","metadata":{},"source":["Next, for each student we'll randomly draw an ability and an effort.\nDraws are from a normal distribution.\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["ability = [random.normalvariate(0,1) for name in names]\n\neffort = [random.normalvariate(0,1) for name in names]"]},{"cell_type":"markdown","metadata":{},"source":["With names, ability, and effort all determined, build a `pandas.DataFrame`.\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["students = pd.DataFrame({'Ability':ability,'Effort':effort}, index=names)\n\nprint(students.head())"]},{"cell_type":"markdown","metadata":{},"source":["### Performance\n\n"]},{"cell_type":"markdown","metadata":{},"source":["If professors could simply observe ability and effort, grading would\nbe very easy!  That's not the world we live in, though.  Instead we\nhave students take tests or complete assignments, where performance is\nrelated to effort and ability, and we try to draw inferences about\nthe latter from the former.\n\nThe following code assigns students to random teams, and generates\nscores for their projects.  Note that, e.g., \"Team1\" means the\nassignment to teams for project 1; it's not an identifier for a team.\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import numpy as np\n# Assign students to random groups and generate project scores.\n\nPROJECTS = 4\nTEAMS = 8\n\nfor project in range(PROJECTS):\n    # Sort students into a random order\n    np.random.shuffle(names)\n\n    students = students.join(pd.Series(np.array([[i]*(STUDENTS // TEAMS)\n                                                 for i in range(TEAMS)]).flatten(),\n                                       index=names,name='Team%d' % (project+1,)))\nprint(students.head())"]},{"cell_type":"markdown","metadata":{},"source":["Now, performance on each group project is assumed to depend on the\naverage of the of ability and effort for the entire team.  Every\nstudent will provide a *ranking* of all *other* teams' projects.\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["for project in range(1,PROJECTS+1):\n    teams = students.groupby('Team%d' % project)\n    teamscore = teams[['Ability','Effort']].mean().sum(axis=1) # Team averages\n    others_evals = teamscore.values.reshape((-1,1))\n                 + np.random.randn(TEAMS,int(STUDENTS*(TEAMS-1)/TEAMS)) # Others' evals\n    others_evals = pd.DataFrame(others_evals).rank(ascending=False).mean(axis=1).squeeze() # Average of rankings\n    others_evals.name = 'Project%d' % project\n    students = students.join(others_evals,on='Team%d' % project)\n\nprint(students.filter(regex=\"Project\").head())"]},{"cell_type":"markdown","metadata":{},"source":["So far so good; we have averages of rankings of all students for\nothers' team projects.  The second source of assessment are peer\nrankings *within* the group.  We assume that one's teammates provide\nrankings which depend on ability and effort, observed with error.\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["for project in range(1,PROJECTS+1):\n    \n    peer_evals = students[['Ability','Effort']].sum(axis=1).values.reshape((-1,1))\n    peer_evals = peer_evals + np.random.randn(STUDENTS,STUDENTS//TEAMS + 1) # Error in obs.\n    peer_evals = pd.DataFrame(peer_evals,index=students.index).rank(ascending=False).mean(axis=1).squeeze() # Average of rankings\n    students['Peers%d' % project] = peer_evals\n\nprint(students.filter(regex=\"Peers\").head(10))\n#print(peer_evals)"]},{"cell_type":"markdown","metadata":{},"source":["Finally, there's also individual assessments, from the final exam and\ninstructor assessment of contributions on `piazza`.  These are also\nrelated to ability and effort, measured with error.  However, we\nassume that contributions on piazza depend more on effort than on\nability.\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"# Out[24]:\n# output\n  File \"<ipython-input-24-7458272908cd>\", line 1\n    students['Final'] = students[['Ability','Effort']].sum(axis=1) +\n                                                                    ^\nSyntaxError: invalid syntax"}],"source":["students['Final'] = students[['Ability','Effort']].sum(axis=1) \nstudents['Final'] = students['Final'] + np.random.randn(STUDENTS)*0.2\n\n# Effort weighted 0.7, ability 0.3\nstudents['piazza'] = students[['Ability','Effort']].dot([.3,.7]) + np.random.randn(STUDENTS)*0.5"]},{"cell_type":"markdown","metadata":{},"source":["Taken altogether, this gives us a DataFrame of scores by student.\nThis is more or less what the data I'll have at the end of the\nsemester will look like (except that the names will be less silly).\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["# Note that *lower* rankings are better, so flip sign on scores based on such rankings\nScores = pd.concat([students[['Final','piazza']],\n                    -students[['Peers%d' % p for p in range(1,PROJECTS+1)]+['Project%d' % p for p in range(1,PROJECTS+1)]]],axis=1)\n\nprint(Scores.head())"]},{"cell_type":"markdown","metadata":{},"source":["## Evaluation\n\n"]},{"cell_type":"markdown","metadata":{},"source":["So, how do we turn a set of scores like this into course grades?\nThere are two steps.  First, we compute the *singular value\ndecomposition* (SVD) of the matrix of scores; this is a technique\nfundamental the the calculation of least squares regression\ntechniques, and a popular tool in the recent machine learning\nliterature.  It's closely related to an approach called \"principal\ncomponents\" which has long been used in a field called \"psychometrics\", which does things \nlike designing and interpreting intelligence tests.   \n\nA great feature of the SVD is that it allows us to *simultaneously*\nestimate ability+effort for each student, along with a weight for each\nassignment that indicates how informative that assignment is.\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["#!pip install CFEDemands --upgrade\nfrom cfe.estimation import svd_rank1_approximation_with_missing_data as my_svd\n\n# Windsorize scores (helps interpretation)\nScores = Scores - Scores.mean()\nScores = Scores/Scores.std()\n\nxhat,weights,s,grades = my_svd(Scores,return_usv=True)\n\n# Sign from SVD is indeterminate, but weights should be positive\nif weights.sum()<0:\n    weights = -weights\n    grades = - grades\n    \nweights = weights/weights.sum()\n\n# Normalize grades\ngrades = (grades-grades.mean())/grades.std()\n\nprint(weights)"]},{"cell_type":"markdown","metadata":{},"source":["The right measure of success for this approach is if the grades we assign provide a good estimate of the sum of ability and effort.\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import cufflinks as cf\nfrom plotly.io import write_image\ncf.go_offline()\n\n# This is what we want to measure\ntruth = students[['Ability','Effort']].sum(axis=1) \n\ndf = pd.DataFrame({'Truth':truth,'Grades':grades})\nprint(df.corr().iloc[0,1])\n\ndf.iplot(kind='scatter', mode='markers', symbol='circle-dot',\n         x='Truth',y='Grades',\n         xTitle='Truth',yTitle='Grades',\n         asFigure=False)\n\n#write_image(fig,'grades_vs_truth.png')"]},{"cell_type":"markdown","metadata":{},"source":["## Grade Assignment\n\n"]},{"cell_type":"markdown","metadata":{},"source":["We've described above how we'll calculate *scores*; how will these be\nturned into letter grades?  Let's start with a description of the\ndistribution of scores from above; these have been /normalized, so\nthat they have a mean of zero and a standard deviation of one, by\nconstruction.\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["grades.iplot(kind='histogram',\n             xTitle='Grade (raw)',\n             yTitle='Frequency')"]},{"cell_type":"markdown","metadata":{},"source":["To map into letter grades, we'll using the following device, which\ninvolves anchoring letter grades to the best five students.\n\n-   Let $\\bar{x}$ be the median grade among top five students (i.e.,\n    the 3rd highest grade, if we ignore ties).\n-   All students with a grade greater than $\\bar{x}-1/3$ will receive\n    an **A+** (so *at least* best three students will receive this\n    grade, by construction).\n-   Remaining students within 2/3 of a standard deviation of $\\bar{x}$\n    will receive an **A**.\n-   Remaining students within one standard deviation of $\\bar{x}$\n    will receive an **A-**.\n-   And so on&#x2026;\n-   &#x2026;until students with grades more than 4 standard deviations of\n    $\\bar{x}$ will receive an **F**.\n\nIf scores are normally distributed, then we'd expect $\\bar{x}$ to be\nabout 1.517 standard deviations above the mean, and for the\ndistribution of grades to be as follows.  (NB: The assumption of\nnormality is a big assumption! However, if it's satisfied then our\ndistribution of grades will be close to the distribution reported for\nall EEP classes: [http://projects.dailycal.org/grades/](http://projects.dailycal.org/grades/))  \n\n| Normalized Grade Score|Letter|Predicted %|\n|---|---|---|\n| $\\bar{x}-x\\leq 1/3$|A+|11.97%|\n| $2/3\\leq \\bar{x}-x < 1/3$|A|7.99%|\n| $1\\leq \\bar{x}-x< 2/3$|A-|10.55%|\n| $4/3\\leq \\bar{x}-x< 1$|B+|12.49%|\n| $5/3\\leq \\bar{x}-x< 4/3$|B|13.24%|\n| $2\\leq \\bar{x}-x< 5/3$|B-|12.57%|\n| $7/3\\leq \\bar{x}-x< 2$|C+|10.69%|\n| $8/3\\leq \\bar{x}-x< 7/3$|C|8.15%|\n| $3\\leq \\bar{x}-x< 8/3$|C-|5.56%|\n| $10/3\\leq \\bar{x}-x< 3$|D+|3.40%|\n| $11/3\\leq\\bar{x}- x< 10/3$|D|1.86%|\n| $4\\leq \\bar{x}-x< 11/3$|D-|0.91%|\n| $\\bar{x}-x > 4$|F|0.64%|\n\n"]},{"cell_type":"markdown","metadata":{},"source":["## Details\n\n"]},{"cell_type":"markdown","metadata":{},"source":["How do we know what the expected value of the third highest score is?\nFor measures of centrality like the mean we have a nice theory\ngoverning its distribution (the mean will be asymptotically normally\ndistributed with a standard deviation of $1/\\sqrt{N}$, where $N$ is\nthe class size).  Similar results hold for estimating any *quantile*\nof the distribution, and follow from the Central Limit Theorem.  \n\nThese results *can't* be used for things like the value of the $k$th\nhighest score as the population gets large.  There is a collection of\ntheoretical results that *does* obtain, collectively called \"Extreme\nvalue theory\".  \n\nInstead of heading to the math library, we will cheat.  Let's just\n**draw** a large number of samples of scores from a (quasi-) random\nnumber generator.  Each sample will just be the size of the class\n(e.g., 40).  Then for each sample we'll find the third-highest value,\nand compute the average across all the samples.  \n\nThis approach to calculating a statistic is called a \"Monte Carlo\"\nexperiment, and is often very effective (even if a bit crude).\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import numpy as np\n\nSTUDENTS=40\n\nxbar=[]\nfor i in range(10000):\n    x = np.random.randn(STUDENTS)\n    x.sort()\n    xbar.append(x[-3]) \n\nprint(\"Estimated value of xbar is: {:2f}.\".format(np.mean(xbar)))\npd.DataFrame({\"xbar\":xbar}).iplot(kind='histogram',bins=100)"]}],"metadata":{"org":null,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}